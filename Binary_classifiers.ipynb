{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4e9f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from itertools import product\n",
    "from collections import Counter\n",
    "import statistics\n",
    "#scikit-learn modules\n",
    "from sklearn import ensemble, linear_model, metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import manifold\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import KFold, cross_val_score,cross_val_predict,train_test_split\n",
    "from sklearn.utils import resample\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "#plotting\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "525ca80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#amino acid position for sparse encoding\n",
    "aa_pos = {\"A\":0,\"C\":1,\"D\":2,\"E\":3,\"F\":4,\"G\":5,\"H\":6,\"I\":7,\"K\":8,\"L\":9,\"M\":10,\"N\":11,\"P\":12,\"Q\":13,\"R\":14,\"S\":15,\"T\":16,\"V\":17,\"W\":18,\"Y\":19,\"-\":20}\n",
    "#blosum62 substitution matrix\n",
    "aa_blosum62 = {\"A\":np.asarray([4,0,-2,-1,-2,0,-2,-1,-1,-1,-1,-2,-1,-1,-1,1,0,0,-3,-2,-100]),\n",
    "          \"C\":np.asarray([0,9,-3,-4,-2,-3,-3,-1,-3,-1,-1,-3,-3,-3,-3,-1,-1,-1,-2,-2,-100]),\n",
    "          \"D\":np.asarray([-2,-3,6,2,-3,-1,-1,-3,-1,-4,-3,1,-1,0,-2,0,-1,-3,-4,-3,-100]),\n",
    "          \"E\":np.asarray([-1,-4,-2,5,-3,-2,0,-3,1,-3,-2,0,-1,2,0,0,-1,-2,-3,-2,-100]),\n",
    "          \"F\":np.asarray([-2,-2,-3,-3,6,-3,-1,0,-3,0,0,-3,-4,-3,-3,-2,-2,-1,1,3,-100]),\n",
    "          \"G\":np.asarray([0,-3,-1,-2,-3,6,-2,-4,-2,-4,-3,0,-2,-2,-2,0,-2,-3,-2,-3,-100]),\n",
    "          \"H\":np.asarray([-2,-3,-1,0,-1,-2,8,-3,-1,-3,-2,1,-2,0,0,-1,-2,-3,-2,2,-100]),\n",
    "          \"I\":np.asarray([-1,-1,-3,-3,0,-4,-3,4,-3,2,1,-3,-3,-3,-3,-2,-1,3,-3,-1,-100]),\n",
    "          \"K\":np.asarray([-1,-3,-1,-1,-3,-2,-1,-3,5,-2,-1,0,-1,1,2,0,-1,-2,-3,-2,-100]),\n",
    "          \"L\":np.asarray([-1,-1,-4,-3,0,-4,-3,2,-2,4,2,-3,-3,-2,-2,-2,-1,1,-2,-1,-100]),\n",
    "          \"M\":np.asarray([-1,-1,-3,-2,0,-3,-2,1,-1,2,5,-2,-2,0,-1,-1,-1,1,-1,-1,-100]),\n",
    "          \"N\":np.asarray([-2,-3,1,0,-3,0,1,-3,0,-3,-2,6,-2,0,0,1,0,-3,-4,-2,-100]),\n",
    "          \"P\":np.asarray([-1,-3,-1,-1,-4,-2,-2,-3,-1,-3,-2,-2,7,-1,-2,-1,-1,-2,-4,-3,-100]),\n",
    "          \"Q\":np.asarray([-1,-3,-0,2,-3,-2,0,-3,1,-2,0,0,-1,5,1,0,-1,-2,-2,-1,-100]),\n",
    "          \"R\":np.asarray([-1,-3,-2,0,-3,-2,0,-3,2,-2,-1,0,-2,1,5,-1,-1,-3,-3,-2,-100]),\n",
    "          \"S\":np.asarray([1,-1,0,0,-2,0,-1,-2,0,-2,-1,-1,-1,0,-1,4,1,-2,-3,-2,-100]),\n",
    "          \"T\":np.asarray([0,-1,-1,-1,-2,-2,-2,-1,-1,-1,-1,0,-1,-1,-1,1,5,0,-2,-2,100]),\n",
    "          \"V\":np.asarray([0,-1,-3,-2,-1,-3,-3,3,-2,1,1,-3,-2,-2,-3,-2,0,4,-3,-1,-100]),\n",
    "          \"W\":np.asarray([-3,-2,-4,-3,1,-2,-2,-3,-3,-2,-1,-4,-4,-2,-3,-3,-2,-3,11,2,-100]),\n",
    "          \"Y\":np.asarray([-2,-2,-3,-2,3,-3,2,-1,-2,-1,-1,-2,-3,-1,-2,-2,-2,-1,2,7,-100]),\n",
    "          \"-\":np.asarray([-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,-100,100,-100,-100,0])}\n",
    "#amino acid combination for 3-mer encoding\n",
    "aa = [\"A\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\", \"N\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"V\", \"W\", \"Y\"]\n",
    "combinations_list = [\"\".join(comb) for comb in product(aa, repeat=3)]\n",
    "\n",
    "#sparse encoding: for each amino acid there is a vector of 20 elements in which the only 1 is the one corresponding to the amino acid in that position, the rest are 0s\n",
    "def sparse_peptide(peptide_list): \n",
    "    pept_vector = np.zeros((len(peptide_list),100,21,1))\n",
    "    counter = 0\n",
    "    counter_list = 0\n",
    "    for peptide in peptide_list:\n",
    "        if len(peptide) > 100:\n",
    "            peptide = peptide[0:100]\n",
    "        for i in range(len(peptide)):\n",
    "            pept_vector[counter_list,i,aa_pos[peptide[i]]]=1\n",
    "        for j in range(len(peptide),100):\n",
    "            pept_vector[counter_list,j,aa_pos[\"-\"]]=1\n",
    "        counter_list +=1\n",
    "    lista = np.zeros((len(peptide_list),2100))\n",
    "    for i in range(len(pept_vector)):\n",
    "        lista[i] = pept_vector[i].flatten()\n",
    "    return lista\n",
    "\n",
    "#denser encoding where for each position of a vector of lenght 100 there is one number representing a specific aa\n",
    "def denser_peptide(peptide_list):\n",
    "    pept_vector = np.zeros((len(peptide_list),100))\n",
    "    counter_list = 0\n",
    "    for peptide in peptide_list:\n",
    "        if len(peptide) > 100:\n",
    "            peptide = peptide[0:100]\n",
    "        for i in range(len(peptide)):\n",
    "            pept_vector[counter_list,i]=aa_pos[peptide[i]]\n",
    "        counter_list +=1\n",
    "    return pept_vector\n",
    "\n",
    "#for each position of the peptide amino acid there is a vector of 21 elements with the substitution scores of the blosum62 matrix\n",
    "def blosum_substitution(peptide_list):\n",
    "    pept_vector = np.zeros((len(peptide_list),100,21))\n",
    "    counter = 0\n",
    "    counter_list = 0\n",
    "    for peptide in peptide_list:\n",
    "        if len(peptide) > 100:\n",
    "            peptide = peptide[0:100]\n",
    "        for i in range(len(peptide)):\n",
    "            pept_vector[counter_list,i]=aa_blosum62[peptide[i]]\n",
    "            counter += 1\n",
    "        for j in range(counter,100):\n",
    "            pept_vector[counter_list,j]=aa_blosum62[\"-\"]\n",
    "        counter_list +=1\n",
    "        counter = 0\n",
    "    lista = np.zeros((len(peptide_list),2100))\n",
    "    for i in range(len(pept_vector)):\n",
    "        lista[i] = pept_vector[i].flatten()\n",
    "    return lista\n",
    "\n",
    "#for each peptide the 3mers are calculated with a sliding window and their number are added to a vector with all the combinations\n",
    "def threemers(peptide_list):\n",
    "    pept_vector = np.zeros((len(peptide_list),8000))\n",
    "    counter_list = 0\n",
    "    for peptide in peptide_list:\n",
    "        if len(peptide) > 100:\n",
    "            peptide = peptide[0:100]\n",
    "        counts = {aa_comb: 0 for aa_comb in combinations_list}\n",
    "        for i in range(len(peptide)-2):\n",
    "            window = peptide[i:i+3]\n",
    "            if window in counts:\n",
    "                counts[window] += 1\n",
    "        pept_vector[counter_list]=list(counts.values())\n",
    "        counter_list +=1\n",
    "    return pept_vector\n",
    "\n",
    "peptides_df = pd.read_csv(\"DB/DB_hyperfiltered.csv\") #load files with peptide sequencies and function\n",
    "funzioni = peptides_df.Function.unique()\n",
    "vectors = [sparse_peptide,denser_peptide,blosum_substitution,threemers]\n",
    "logistic_regression = linear_model.LogisticRegression(penalty='l1', solver='liblinear', C=1, class_weight=\"balanced\")\n",
    "random_forest = ensemble.RandomForestClassifier(class_weight = \"balanced\")\n",
    "kneighbor = neighbors.KNeighborsClassifier(62, weights=\"distance\")\n",
    "support_vector_machine = svm.SVC(kernel='linear', probability=True, C=0.1, class_weight = \"balanced\")\n",
    "classifiers = [logistic_regression,random_forest,kneighbor,support_vector_machine]\n",
    "#some dictionaries to store stats of training\n",
    "logreg = {\"sparse_peptide\":{},\"denser_peptide\":{}, \"blosum_substitution\":{}, \"threemers\":{}}\n",
    "randfor = {\"sparse_peptide\":{},\"denser_peptide\":{}, \"blosum_substitution\":{}, \"threemers\":{}}\n",
    "kneigh = {\"sparse_peptide\":{},\"denser_peptide\":{}, \"blosum_substitution\":{}, \"threemers\":{}}\n",
    "suppvem = {\"sparse_peptide\":{},\"denser_peptide\":{}, \"blosum_substitution\":{}, \"threemers\":{}}\n",
    "\n",
    "classifier_dict = [logreg,randfor,kneigh,suppvem]\n",
    "for c in classifier_dict: #nested dictionary for the results\n",
    "    for i in c:\n",
    "        for j in funzioni:\n",
    "            c[i][j]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da80f56a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#up until this it was the same as GridSearch.ipynb\n",
    "parameters_dicts = [{'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 200},\n",
    "{'criterion': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 200},\n",
    "{'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 10},\n",
    "{'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 100},\n",
    "{'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 50},\n",
    "{'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 100},\n",
    "{'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 200},\n",
    "{'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 10},\n",
    "{'criterion': 'log_loss', 'max_features': 'log2', 'n_estimators': 200}] #load the best hyperparameters for each class\n",
    "for j in range(len(funzioni)):  #for every function use the best parameters to create the classifier, train it and save it\n",
    "    dizio_h = parameters_dicts[j]\n",
    "    funzione = funzioni[j]\n",
    "    clf = ensemble.RandomForestClassifier(class_weight = \"balanced\", criterion = dizio_h[\"criterion\"], max_features = dizio_h[\"max_features\"], n_estimators = dizio_h[\"n_estimators\"])\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    train_MCC = []\n",
    "    test_MCC = []\n",
    "    train_rocauc = []\n",
    "    test_rocauc = []\n",
    "    for i in range(1): #train the model once using the best hyperparameters than save the model\n",
    "        peptides_df = pd.read_csv(\"DB/DB_hyperfiltered.csv\")\n",
    "        peptides_df.loc[peptides_df[\"Function\"] == funzione, \"Class\"] = 0 #set the class of interest to have label 0, the rest are 1\n",
    "        functions = peptides_df[\"Class\"]\n",
    "        all_data = denser_peptide(peptides_df[\"Sequence\"])\n",
    "        X_train, X_test, y_train, y_test = model_selection.train_test_split(all_data,functions, stratify=functions, test_size=0.3) #default is 70/30\n",
    "        clf.fit(X_train,y_train)\n",
    "        predictions = clf.predict(X_train)\n",
    "        predicted = clf.predict(X_test)\n",
    "        train_acc.append(metrics.accuracy_score(y_train,predictions))\n",
    "        test_acc.append(metrics.accuracy_score(y_test,predicted))\n",
    "        train_MCC.append(matthews_corrcoef(y_train,predictions))\n",
    "        test_MCC.append(matthews_corrcoef(y_test,predicted))\n",
    "        train_rocauc.append(metrics.roc_auc_score(y_train,predictions))\n",
    "        test_rocauc.append(metrics.roc_auc_score(y_test,predicted))\n",
    "        filename = str(funzione)+\".sav\"\n",
    "        pickle.dump(clf, open(filename, 'wb'))\n",
    "    #print(statistics.mean(train_acc),\"\\t\", statistics.stdev(train_acc),\"\\t\", statistics.mean(test_acc),\"\\t\",statistics.stdev(test_acc),\"\\t\", statistics.mean(train_MCC),\"\\t\", statistics.stdev(train_MCC),\"\\t\", statistics.mean(test_MCC),\"\\t\",statistics.stdev(test_MCC),\"\\t\", statistics.mean(train_rocauc),\"\\t\",statistics.stdev(train_rocauc),\"\\t\", statistics.mean(test_rocauc),\"\\t\",statistics.stdev(test_rocauc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0333a71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
